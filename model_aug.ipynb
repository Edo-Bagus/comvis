{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edada46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "column_names = ['Image', 'Attention']\n",
    "\n",
    "df_attention = pd.read_csv('attention.csv', header=None, names=column_names)\n",
    "df_shape_train = pd.read_csv('./featurebyshape/shape_train.csv')\n",
    "df_shape_train_aug = pd.read_csv('./featurebyshape/shape_train_aug.csv')\n",
    "df_shape_test = pd.read_csv('./featurebyshape/shape_test.csv')\n",
    "\n",
    "df_color_train = pd.read_csv('./featurebycolor/color_train.csv')\n",
    "df_color_train_aug = pd.read_csv('./featurebycolor/color_train_aug.csv')\n",
    "df_color_test = pd.read_csv('./featurebycolor/color_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d7fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape_train['image_name'] = df_shape_train['image_name'].apply(lambda x: int(os.path.splitext(x.split('/')[-1])[0]))\n",
    "df_merged = pd.merge(df_shape_train, df_color_train, on='image_name', how='inner')\n",
    "\n",
    "df_shape_train_aug['image_name'] = df_shape_train_aug['image_name'].apply(lambda x: os.path.splitext(x.split('/')[-1])[0])\n",
    "df_merged_aug = pd.merge(df_shape_train_aug, df_color_train_aug, on='image_name', how='inner')\n",
    "\n",
    "df_shape_test['image_name'] = df_shape_test['image_name'].apply(lambda x: int(os.path.splitext(x.split('/')[-1])[0]))\n",
    "df_merged_test = pd.merge(df_shape_test, df_color_test, on='image_name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attention.rename(columns={'Image': 'image_name'}, inplace=True)\n",
    "df_attention['image_name'] = df_attention['image_name'].apply(lambda x: int(os.path.splitext(x.split('/')[-1])[0]))\n",
    "df_merged_aug['image_name'] = df_merged_aug['image_name'].str.split('_').str[0].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812220d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged = pd.merge(df_merged, df_attention, on='image_name', how='inner')\n",
    "df_merged_aug = pd.merge(df_merged_aug, df_attention, on='image_name', how='inner')\n",
    "df_merged_test = pd.merge(df_merged_test, df_attention, on='image_name', how='inner')\n",
    "\n",
    "df_merged =  pd.concat([df_merged, df_merged_aug], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73bc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.dropna()\n",
    "df_merged_test = df_merged_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94651edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def expand_list_column(df, list_column):\n",
    "    # Konversi string menjadi list\n",
    "    df[list_column] = df[list_column].apply(ast.literal_eval)\n",
    "    \n",
    "    # Pisahkan list menjadi kolom terpisah dan tambahkan ke dataframe\n",
    "    for i in range(8):  # Asumsi list panjangnya 8\n",
    "        df[f'{list_column}_col_{i+1}'] = df[list_column].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "    # Hapus kolom asli jika tidak diperlukan\n",
    "    df = df.drop(columns=[list_column])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Terapkan fungsi\n",
    "df_merged = expand_list_column(df_merged, 'edge_orientation_histogram')\n",
    "df_merged = df_merged.drop(columns=['image_name'])\n",
    "\n",
    "df_merged_test = expand_list_column(df_merged_test, 'edge_orientation_histogram')\n",
    "df_merged_test = df_merged_test.drop(columns=['image_name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a36448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Kolom kategorikal yang perlu diproses\n",
    "categorical_columns = ['dominant_text_position', 'font_variety_estimation', 'readability']\n",
    "\n",
    "# Label Encoding untuk kolom yang memiliki urutan\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Lakukan Label Encoding pada kolom kategorikal dan ubah menjadi tipe int\n",
    "for col in categorical_columns:\n",
    "    df_merged[col] = label_encoder.fit_transform(df_merged[col].astype(str))\n",
    "    df_merged_test[col] = label_encoder.transform(df_merged_test[col].astype(str))\n",
    "\n",
    "# Pastikan tipe data kolom menjadi int\n",
    "df_merged[categorical_columns] = df_merged[categorical_columns].astype(int)\n",
    "df_merged_test[categorical_columns] = df_merged_test[categorical_columns].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6cdfb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi kelas setelah SMOTE dan RandomUnderSampler: Attention\n",
      "4    88\n",
      "3    88\n",
      "2    88\n",
      "0    88\n",
      "1    85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = df_merged.drop(columns=['Attention'])\n",
    "y_train = df_merged['Attention']\n",
    "X_test = df_merged_test.drop(columns=['Attention'])\n",
    "y_test = df_merged_test['Attention']\n",
    "\n",
    "# Mengecek distribusi kelas setelah oversampling dan undersampling\n",
    "print(\"Distribusi kelas setelah SMOTE dan RandomUnderSampler:\", y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41910d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\comvis\\comvis\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:19:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'subsample': 0.8, 'scale_pos_weight': 1, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1.0}\n",
      "Akurasi: 0.3728813559322034\n",
      "Laporan Klasifikasi:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.17      0.09      0.12        11\n",
      "           2       0.25      0.25      0.25         8\n",
      "           3       0.11      0.10      0.11        10\n",
      "           4       0.47      0.60      0.53        25\n",
      "\n",
      "    accuracy                           0.37        59\n",
      "   macro avg       0.35      0.33      0.33        59\n",
      "weighted avg       0.35      0.37      0.35        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Inisialisasi model XGBoost\n",
    "xgb = XGBClassifier(random_state=42)  # disable categorical mode\n",
    "\n",
    "# Tentukan distribusi hyperparameters yang ingin diuji\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'scale_pos_weight': [1, 5, 10],  # Menyeimbangkan kelas yang tidak seimbang\n",
    "}\n",
    "\n",
    "# Gunakan RandomizedSearchCV untuk mencari kombinasi hyperparameter terbaik\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50,  # Jumlah iterasi pencarian\n",
    "    cv=5,  # Cross-validation\n",
    "    n_jobs=-1,  # Gunakan semua core CPU\n",
    "    scoring='accuracy', \n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Latih model dengan RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Tampilkan hyperparameter terbaik yang ditemukan\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Gunakan model terbaik yang ditemukan untuk prediksi\n",
    "best_xgb_random = random_search.best_estimator_\n",
    "y_pred = best_xgb_random.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdcbcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'class_weight': None, 'bootstrap': False}\n",
      "Akurasi: 0.3898305084745763\n",
      "Laporan Klasifikasi:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50         5\n",
      "           1       0.29      0.18      0.22        11\n",
      "           2       0.33      0.12      0.18         8\n",
      "           3       0.10      0.10      0.10        10\n",
      "           4       0.47      0.68      0.56        25\n",
      "\n",
      "    accuracy                           0.39        59\n",
      "   macro avg       0.37      0.30      0.31        59\n",
      "weighted avg       0.37      0.39      0.36        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Inisialisasi model Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Tentukan distribusi hyperparameters yang ingin diuji\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': [None, 'balanced']  # Menyeimbangkan kelas jika tidak seimbang\n",
    "}\n",
    "\n",
    "# Gunakan RandomizedSearchCV untuk mencari kombinasi hyperparameter terbaik\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50,  # Jumlah iterasi pencarian\n",
    "    cv=5,  # Cross-validation\n",
    "    n_jobs=-1,  # Gunakan semua core CPU\n",
    "    scoring='accuracy', \n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Latih model dengan RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Tampilkan hyperparameter terbaik yang ditemukan\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Gunakan model terbaik yang ditemukan untuk prediksi\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9cea0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters: {'weights': 'uniform', 'n_neighbors': 1, 'metric': 'manhattan'}\n",
      "Akurasi: 0.3050847457627119\n",
      "Laporan Klasifikasi:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.60      0.46         5\n",
      "           1       0.38      0.27      0.32        11\n",
      "           2       0.23      0.38      0.29         8\n",
      "           3       0.14      0.20      0.17        10\n",
      "           4       0.44      0.28      0.34        25\n",
      "\n",
      "    accuracy                           0.31        59\n",
      "   macro avg       0.31      0.35      0.31        59\n",
      "weighted avg       0.34      0.31      0.31        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Inisialisasi model KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Tentukan distribusi hyperparameters\n",
    "param_dist = {\n",
    "    'n_neighbors': list(range(1, 31)),  # Jumlah tetangga\n",
    "    'weights': ['uniform', 'distance'],  # Bobot\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']  # Metode pengukuran jarak\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=knn,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Latih model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Tampilkan hyperparameter terbaik\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Gunakan model terbaik untuk prediksi\n",
    "best_knn = random_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4af9c0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best Hyperparameters: {'solver': 'adam', 'max_iter': 2000, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 5000, 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Akurasi: 0.23728813559322035\n",
      "Laporan Klasifikasi:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40         5\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.11      0.20      0.14        10\n",
      "           4       0.30      0.36      0.33        25\n",
      "\n",
      "    accuracy                           0.24        59\n",
      "   macro avg       0.14      0.23      0.17        59\n",
      "weighted avg       0.17      0.24      0.20        59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\comvis\\comvis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\comvis\\comvis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\comvis\\comvis\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Inisialisasi model MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Tentukan distribusi hyperparameters yang ingin diuji\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(200,), (500), (1000), (2000), (5000)],  # Jumlah neuron di setiap layer\n",
    "    'activation': ['relu', 'tanh'],  # Fungsi aktivasi\n",
    "    'solver': ['adam', 'sgd'],  # Optimizer yang digunakan\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularisasi\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],  # Laju pembelajaran\n",
    "    'max_iter': [200, 300, 500, 1000, 2000]  # Iterasi maksimum untuk pelatihan\n",
    "}\n",
    "\n",
    "# Gunakan RandomizedSearchCV untuk mencari kombinasi hyperparameter terbaik\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=mlp, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50,  # Jumlah iterasi pencarian\n",
    "    cv=5,  # Cross-validation\n",
    "    n_jobs=-1,  # Gunakan semua core CPU\n",
    "    scoring='accuracy', \n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Latih model dengan RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Tampilkan hyperparameter terbaik yang ditemukan\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Gunakan model terbaik yang ditemukan untuk prediksi\n",
    "best_mlp_random = random_search.best_estimator_\n",
    "y_pred = best_mlp_random.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
